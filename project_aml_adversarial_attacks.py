# -*- coding: utf-8 -*-
"""Project_AML_Adversarial_Attacks.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lJgcXt-f-hAibjKJdiR1M585w0WPUzoJ

Team Members:

1. Disha Chakraborty- R11907830
2. Gitanjali Ghosh- R11903434
3. Afshan Javed- R11985175
4. Nusrat Anjum Dina- R11875958

##Topic - Adversarial attacks on Deep Image Classification models using FGSM and Adversarial Patch Attack
"""

# Commented out IPython magic to ensure Python compatibility.
## Standard libraries
import os
import json
import math
import time
import numpy as np
import scipy.linalg

## Imports for plotting
import matplotlib.pyplot as plt
# %matplotlib inline
from IPython.display import set_matplotlib_formats
set_matplotlib_formats('svg', 'pdf') # For export
from matplotlib.colors import to_rgb
import matplotlib
matplotlib.rcParams['lines.linewidth'] = 2.0
import seaborn as sns
sns.set()

## Progress bar
from tqdm.notebook import tqdm

## PyTorch
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.utils.data as data
import torch.optim as optim
# Torchvision
import torchvision
from torchvision.datasets import CIFAR10
from torchvision import transforms
# PyTorch Lightning
try:
    import pytorch_lightning as pl
except ModuleNotFoundError: # Google Colab does not have PyTorch Lightning installed by default. Hence, we do it here if necessary
    !pip install --quiet pytorch-lightning>=1.4
    import pytorch_lightning as pl
from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint

# Path to the folder where the datasets are/should be downloaded (e.g. MNIST)
DATASET_PATH = "../data"
# Path to the folder where the pretrained models are saved
CHECKPOINT_PATH = "../saved_models/tutorial10"

# Setting the seed
pl.seed_everything(42)

# Ensure that all operations are deterministic on GPU (if used) for reproducibility
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

# Fetching the device that will be used throughout this notebook
device = torch.device("cpu") if not torch.cuda.is_available() else torch.device("cuda:0")
print("Using device", device)

import urllib.request
from urllib.error import HTTPError
import zipfile
# Github URL where the dataset is stored for this tutorial
base_url = "https://raw.githubusercontent.com/phlippe/saved_models/main/tutorial10/"
# Files to download
pretrained_files = [(DATASET_PATH, "TinyImageNet.zip"), (CHECKPOINT_PATH, "patches.zip")]
# Create checkpoint path if it doesn't exist yet
os.makedirs(DATASET_PATH, exist_ok=True)
os.makedirs(CHECKPOINT_PATH, exist_ok=True)

# For each file, check whether it already exists. If not, try downloading it.
for dir_name, file_name in pretrained_files:
    file_path = os.path.join(dir_name, file_name)
    if not os.path.isfile(file_path):
        file_url = base_url + file_name
        print(f"Downloading {file_url}...")
        try:
            urllib.request.urlretrieve(file_url, file_path)
        except HTTPError as e:
            print("Something went wrong. Please try to download the file from the GDrive folder, or contact the author with the full output including the following error:\n", e)
        if file_name.endswith(".zip"):
            print("Unzipping file...")
            with zipfile.ZipFile(file_path, 'r') as zip_ref:
                zip_ref.extractall(file_path.rsplit("/",1)[0])

"""## Deep CNNs on ImageNet

we used common CNN architectures trained on the ImageNet dataset.
"""

# Load CNN architecture pretrained on ImageNet
os.environ["TORCH_HOME"] = CHECKPOINT_PATH
pretrained_model = torchvision.models.resnet34(weights='IMAGENET1K_V1')
pretrained_model = pretrained_model.to(device)

# No gradients needed for the network
pretrained_model.eval()
for p in pretrained_model.parameters():
    p.requires_grad = False

"""To perform adversarial attacks, we provide a small set of pre-processed images from the original ImageNet dataset as the original ImageNet dataset. Specifically, we have images for each of the 1000 labels of the dataset."""

# Mean and Std from ImageNet
NORM_MEAN = np.array([0.485, 0.456, 0.406])
NORM_STD = np.array([0.229, 0.224, 0.225])
# No resizing and center crop necessary as images are already preprocessed.
plain_transforms = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=NORM_MEAN,
                         std=NORM_STD)
])

# Load dataset and create data loader
imagenet_path = os.path.join(DATASET_PATH, "TinyImageNet/")
assert os.path.isdir(imagenet_path), f"Could not find the ImageNet dataset at expected path \"{imagenet_path}\". " + \
                                     f"Please make sure to have downloaded the ImageNet dataset here, or change the {DATASET_PATH=} variable."
dataset = torchvision.datasets.ImageFolder(root=imagenet_path, transform=plain_transforms)
data_loader = data.DataLoader(dataset, batch_size=32, shuffle=False, drop_last=False, num_workers=8)

# Load label names to interpret the label numbers 0 to 999
with open(os.path.join(imagenet_path, "label_list.json"), "r") as f:
    label_names = json.load(f)

def get_label_index(lab_str):
    assert lab_str in label_names, f"Label \"{lab_str}\" not found. Check the spelling of the class."
    return label_names.index(lab_str)

"""In ImageNet with 1000 classes, there is not always one clear label we can assign an image to. For image classifications over so many classes, a common alternative metric is "Top-5 accuracy", which tells us how many times the true label has been within the 5 most-likely predictions of the model. As models usually perform quite well on those, we report the error (1 - accuracy) instead of the accuracy:"""

#Evaluate the performance of a pre-trained model
def eval_model(dataset_loader, img_func=None):
    tp, tp_5, counter = 0., 0., 0.
    for imgs, labels in tqdm(dataset_loader, desc="Validating..."):
        imgs = imgs.to(device)
        labels = labels.to(device)
        if img_func is not None:
            imgs = img_func(imgs, labels)
        with torch.no_grad():
            preds = pretrained_model(imgs)
        tp += (preds.argmax(dim=-1) == labels).sum()
        tp_5 += (preds.topk(5, dim=-1)[1] == labels[...,None]).any(dim=-1).sum()
        counter += preds.shape[0]
    acc = tp.float().item()/counter
    top5 = tp_5.float().item()/counter
    print(f"Top-1 error: {(100.0 * (1 - acc)):4.2f}%")
    print(f"Top-5 error: {(100.0 * (1 - top5)):4.2f}%")
    return acc, top5

_ = eval_model(data_loader)

"""The ResNet34 achives a decent error rate of 4.3% for the top-5 predictions. We look at some predictions of the model to get more familiar with the dataset. The function below plots an image along with a bar diagram of its predictions. We also prepare it to show adversarial examples for later applications."""

def show_prediction(img, label, pred, K=5, adv_img=None, noise=None):

    if isinstance(img, torch.Tensor):
        # Tensor image to numpy
        img = img.cpu().permute(1, 2, 0).numpy()
        img = (img * NORM_STD[None,None]) + NORM_MEAN[None,None]
        img = np.clip(img, a_min=0.0, a_max=1.0)
        label = label.item()

    # Plot on the left the image with the true label as title.
    # On the right, have a horizontal bar plot with the top k predictions including probabilities
    if noise is None or adv_img is None:
        fig, ax = plt.subplots(1, 2, figsize=(10,2), gridspec_kw={'width_ratios': [1, 1]})
    else:
        fig, ax = plt.subplots(1, 5, figsize=(12,2), gridspec_kw={'width_ratios': [1, 1, 1, 1, 2]})

    ax[0].imshow(img)
    ax[0].set_title(label_names[label])
    ax[0].axis('off')

    if adv_img is not None and noise is not None:
        # Visualize adversarial images
        adv_img = adv_img.cpu().permute(1, 2, 0).numpy()
        adv_img = (adv_img * NORM_STD[None,None]) + NORM_MEAN[None,None]
        adv_img = np.clip(adv_img, a_min=0.0, a_max=1.0)
        ax[1].imshow(adv_img)
        ax[1].set_title('Adversarial')
        ax[1].axis('off')
        # Visualize noise
        noise = noise.cpu().permute(1, 2, 0).numpy()
        noise = noise * 0.5 + 0.5 # Scale between 0 to 1
        ax[2].imshow(noise)
        ax[2].set_title('Noise')
        ax[2].axis('off')
        # buffer
        ax[3].axis('off')

    if abs(pred.sum().item() - 1.0) > 1e-4:
        pred = torch.softmax(pred, dim=-1)
    topk_vals, topk_idx = pred.topk(K, dim=-1)
    topk_vals, topk_idx = topk_vals.cpu().numpy(), topk_idx.cpu().numpy()
    ax[-1].barh(np.arange(K), topk_vals*100.0, align='center', color=["C0" if topk_idx[i]!=label else "C2" for i in range(K)])
    ax[-1].set_yticks(np.arange(K))
    ax[-1].set_yticklabels([label_names[c] for c in topk_idx])
    ax[-1].invert_yaxis()
    ax[-1].set_xlabel('Confidence')
    ax[-1].set_title('Predictions')

    plt.show()
    plt.close()

"""Visualize a few images below:"""

# Get a single batch of examples and their labels
exmp_batch, label_batch = next(iter(data_loader))
with torch.no_grad():
    # Generate predictions for the batch
    preds = pretrained_model(exmp_batch.to(device))
for i in range(1,17,5):
    # Display the image, true label, and predicted label
    show_prediction(exmp_batch[i], label_batch[i], preds[i])

"""The bar plot on the right shows the top-5 predictions of the model with their class probabilities. We denote the class probabilities with "confidence" as it somewhat resembles how confident the network is that the image is of one specific class. Some of the images have a highly peaked probability distribution

## White-box adversarial attacks


### Fast Gradient Sign Method (FGSM)
"""

def fast_gradient_sign_method(model, imgs, labels, epsilon=0.02):
    # Determine prediction of the model
    inp_imgs = imgs.clone().requires_grad_()
    preds = model(inp_imgs.to(device))
    preds = F.log_softmax(preds, dim=-1)
    # Calculate loss by NLL
    loss = -torch.gather(preds, 1, labels.to(device).unsqueeze(dim=-1))
    loss.sum().backward()
    # Update image to adversarial example as written above
    noise_grad = torch.sign(inp_imgs.grad.to(imgs.device))
    fake_imgs = imgs + epsilon * noise_grad
    fake_imgs.detach_()
    return fake_imgs, noise_grad

"""The default value of $\epsilon=0.02$ corresponds to changing a pixel value by about 1 in the range of 0 to 255, e.g. changing 127 to 128."""

# Generate adversarial examples and noise gradients
adv_imgs, noise_grad = fast_gradient_sign_method(pretrained_model, exmp_batch, label_batch, epsilon=0.02)
with torch.no_grad():
    adv_preds = pretrained_model(adv_imgs.to(device))

for i in range(1,17,5):
    # Show original image, true label, adversarial prediction, adversarial image, and noise
    show_prediction(exmp_batch[i], label_batch[i], adv_preds[i], adv_img=adv_imgs[i], noise=noise_grad[i])

# Evaluate the model using adversarial examples generated by FGSM with epsilon=0.02, passed as a preprocessing function
_ = eval_model(data_loader, img_func=lambda x, y: fast_gradient_sign_method(pretrained_model, x, y, epsilon=0.02)[0])

"""The model is fooled on almost every image at least for the top-1 error, and more than half don't have the true label in their top-5. This is a quite significant difference compared to the error rate of 4.3% on the clean images.

## Adversarial Patches

Instead of changing every pixel by a little bit, we can also try to change a small part of the image into whatever values we would like. In other words, we will create a small image patch that covers a minor part of the original image but causes the model to confidentially predict a specific class we choose. This form of attack is an even bigger threat in real-world applications than FSGM.
"""

#Places a patch at random locations on a batch of images
def place_patch(img, patch):
    for i in range(img.shape[0]):
        h_offset = np.random.randint(0,img.shape[2]-patch.shape[1]-1)
        w_offset = np.random.randint(0,img.shape[3]-patch.shape[2]-1)
        img[i,:,h_offset:h_offset+patch.shape[1],w_offset:w_offset+patch.shape[2]] = patch_forward(patch)
    return img

TENSOR_MEANS, TENSOR_STD = torch.FloatTensor(NORM_MEAN)[:,None,None], torch.FloatTensor(NORM_STD)[:,None,None]
def patch_forward(patch):
    # Map patch values from [-infty,infty] to ImageNet min and max
    patch = (torch.tanh(patch) + 1 - 2 * TENSOR_MEANS) / (2 * TENSOR_STD)
    return patch

def eval_patch(model, patch, val_loader, target_class):
    model.eval()
    tp, tp_5, counter = 0., 0., 0.
    with torch.no_grad():
        for img, img_labels in tqdm(val_loader, desc="Validating...", leave=False):
            # For stability, place the patch at 4 random locations per image, and average the performance
            for _ in range(4):
                patch_img = place_patch(img, patch)
                patch_img = patch_img.to(device)
                img_labels = img_labels.to(device)
                pred = model(patch_img)
                # In the accuracy calculation, we need to exclude the images that are of our target class
                # as we would not "fool" the model into predicting those
                tp += torch.logical_and(pred.argmax(dim=-1) == target_class, img_labels != target_class).sum()
                tp_5 += torch.logical_and((pred.topk(5, dim=-1)[1] == target_class).any(dim=-1), img_labels != target_class).sum()
                counter += (img_labels != target_class).sum()
    acc = tp/counter
    top5 = tp_5/counter
    return acc, top5

def patch_attack(model, target_class, patch_size=64, num_epochs=5):
    # Leave a small set of images out to check generalization
    # In most of our experiments, the performance on the hold-out data points
    # was as good as on the training set. Overfitting was little possible due
    # to the small size of the patches.
    train_set, val_set = torch.utils.data.random_split(dataset, [4500, 500])
    train_loader = data.DataLoader(train_set, batch_size=32, shuffle=True, drop_last=True, num_workers=8)
    val_loader = data.DataLoader(val_set, batch_size=32, shuffle=False, drop_last=False, num_workers=4)

    # Create parameter and optimizer
    if not isinstance(patch_size, tuple):
        patch_size = (patch_size, patch_size)
    patch = nn.Parameter(torch.zeros(3, patch_size[0], patch_size[1]), requires_grad=True)
    optimizer = torch.optim.SGD([patch], lr=1e-1, momentum=0.8)
    loss_module = nn.CrossEntropyLoss()

    # Training loop
    for epoch in range(num_epochs):
        t = tqdm(train_loader, leave=False)
        for img, _ in t:
            img = place_patch(img, patch)
            img = img.to(device)
            pred = model(img)
            labels = torch.zeros(img.shape[0], device=pred.device, dtype=torch.long).fill_(target_class)
            loss = loss_module(pred, labels)
            optimizer.zero_grad()
            loss.mean().backward()
            optimizer.step()
            t.set_description(f"Epoch {epoch}, Loss: {loss.item():4.2f}")

    # Final validation
    acc, top5 = eval_patch(model, patch, val_loader, target_class)

    return patch.data, {"acc": acc.item(), "top5": top5.item()}

bye# Load evaluation results of the pretrained patches
json_results_file = os.path.join(CHECKPOINT_PATH, "patch_results.json")
json_results = {}
if os.path.isfile(json_results_file):
    with open(json_results_file, "r") as f:
        json_results = json.load(f)

# If you train new patches, you can save the results via calling this function
def save_results(patch_dict):
    result_dict = {cname: {psize: [t.item() if isinstance(t, torch.Tensor) else t
                                   for t in patch_dict[cname][psize]["results"]]
                           for psize in patch_dict[cname]}
                   for cname in patch_dict}
    with open(os.path.join(CHECKPOINT_PATH, "patch_results.json"), "w") as f:
        json.dump(result_dict, f, indent=4)

def get_patches(class_names, patch_sizes):
    result_dict = dict()

    # Loop over all classes and patch sizes
    for name in class_names:
        result_dict[name] = dict()
        for patch_size in patch_sizes:
            c = label_names.index(name)
            file_name = os.path.join(CHECKPOINT_PATH, f"{name}_{patch_size}_patch.pt")
            # Load patch if pretrained file exists, otherwise start training
            if not os.path.isfile(file_name):
                patch, val_results = patch_attack(pretrained_model, target_class=c, patch_size=patch_size, num_epochs=5)
                print(f"Validation results for {name} and {patch_size}:", val_results)
                torch.save(patch, file_name)
            else:
                patch = torch.load(file_name)
            # Load evaluation results if exist, otherwise manually evaluate the patch
            if name in json_results:
                results = json_results[name][str(patch_size)]
            else:
                results = eval_patch(pretrained_model, patch, data_loader, target_class=c)

            # Store results and the patches in a dict for better access
            result_dict[name][patch_size] = {
                "results": results,
                "patch": patch
            }

    return result_dict

class_names = ['toaster', 'goldfish', 'school bus', 'lipstick', 'pineapple']
patch_sizes = [32, 48, 64]

patch_dict = get_patches(class_names, patch_sizes)
# save_results(patch_dict) # Uncomment if you add new class names and want to save the new results

"""Before looking at the quantitative results, we can actually visualize the patches."""

def show_patches():
    fig, ax = plt.subplots(len(patch_sizes), len(class_names), figsize=(len(class_names)*2.2, len(patch_sizes)*2.2))
    for c_idx, cname in enumerate(class_names):
        for p_idx, psize in enumerate(patch_sizes):
            patch = patch_dict[cname][psize]["patch"]
            patch = (torch.tanh(patch) + 1) / 2 # Parameter to pixel values
            patch = patch.cpu().permute(1, 2, 0).numpy()
            patch = np.clip(patch, a_min=0.0, a_max=1.0)
            ax[p_idx][c_idx].imshow(patch)
            ax[p_idx][c_idx].set_title(f"{cname}, size {psize}")
            ax[p_idx][c_idx].axis('off')
    fig.subplots_adjust(hspace=0.3, wspace=0.3)
    plt.show()
show_patches()

"""Quantitative results."""

# Commented out IPython magic to ensure Python compatibility.
# %%html
# <!-- Some HTML code to increase font size in the following table -->
# <style>
# th {font-size: 120%;}
# td {font-size: 120%;}
# </style>

import tabulate
from IPython.display import display, HTML

def show_table(top_1=True):

    i = 0 if top_1 else 1  # Use the first index for Top-1 results and the second index for Top-5 results
    table = [[name] + [f"{(100.0 * patch_dict[name][psize]['results'][i]):4.2f}%" for psize in patch_sizes]
             # Create the table with class names and results for each patch size
             for name in class_names]
    display(HTML(tabulate.tabulate(table, tablefmt='html', headers=["Class name"] + [f"Patch size {psize}x{psize}" for psize in patch_sizes])))

"""Create a table of top-1 accuracy"""

show_table(top_1=True)

"""top-5 accuracy:"""

show_table(top_1=False)

"""Create some example visualizations of the patch attack in action."""

def perform_patch_attack(patch):
    # Clone the original batch to avoid modifying it directly
    patch_batch = exmp_batch.clone()
    # Place the patch on random locations in each image
    patch_batch = place_patch(patch_batch, patch)
    with torch.no_grad():
        # Get predictions for the patched images
        patch_preds = pretrained_model(patch_batch.to(device))
    for i in range(1,17,5):
        # Display patched image, true label, and predictions
        show_prediction(patch_batch[i], label_batch[i], patch_preds[i])

perform_patch_attack(patch_dict['goldfish'][32]['patch'])

perform_patch_attack(patch_dict['school bus'][64]['patch'])

"""### Transferability of white-box attacks

"""

transfer_model = torchvision.models.densenet121(weights='IMAGENET1K_V1')
transfer_model = transfer_model.to(device)

# No gradients needed for the network
transfer_model.eval()
for p in transfer_model.parameters():
    p.requires_grad = False

class_name = 'pineapple'    # Specify the class name for the patch being tested
patch_size = 64
print(f"Testing patch \"{class_name}\" of size {patch_size}x{patch_size}")
# Evaluate the fooling effectiveness of the patch on the target class using the transfer model
results = eval_patch(transfer_model,
                     patch_dict[class_name][patch_size]["patch"],
                     data_loader,
                     target_class=label_names.index(class_name))
# Print the Top-1 and Top-5 fooling accuracies for the patch
print(f"Top-1 fool accuracy: {(results[0] * 100.0):4.2f}%")
print(f"Top-5 fool accuracy: {(results[1] * 100.0):4.2f}%")

"""# Defense

##Defensive Distillation (FGSM Attack)

1. **Dataset Loading and Preprocessing**
   - TensorFlow Datasets (`tfds`) is used to load a preprocessed subset of ImageNet.
   - Data is split into training and validation sets, with only 10% of the data used for both.
   - Preprocessing includes:
     - Normalizing image pixel values to [0, 1].
     - One-hot encoding labels for use with categorical cross-entropy loss.

2. **Teacher Model**
   - A convolutional neural network (CNN) is defined as the teacher model.
   - The model is trained on the preprocessed training data.
   - Soft labels (predicted probabilities i.e. probaility distributions over all classes) are generated for the training data.

3. **Soft Target Generation**
   - A function `generate_soft_targets` computes soft targets using the teacher model's predictions.
   - Soft targets are stored in a tensor for use during student model training.

4. **Mapping Soft Targets**
   - A mapping function pairs each input image with their corresponding soft targets generated from the teacher model.
   - The processed training dataset (`train_generator`) uses this mapping for distillation training of student model.

5. **Defensive Distillation**
   - A custom loss function `distillation_loss` is defined for the student model.
   - This loss considers the temperature scaling factor `temp` to soften probabilities during training.

6. **Student Model**
   - The student model is defined with the same architecture as the teacher model.
   - It is trained using the soft targets generated by the teacher model and the distillation loss.

7. **Evaluation**
   - Both teacher and student models are evaluated on the test dataset.
   - The results of their accuracies on clean data are displayed.
"""

#Defense distillation using FGSM attack

import tensorflow as tf
import tensorflow_datasets as tfds

# Load a subset of ImageNet
dataset, info = tfds.load('imagenet_resized/32x32', split=['train[:10%]', 'validation[:10%]'], with_info=True)
train_dataset, test_dataset = dataset
num_classes = info.features['label'].num_classes  # Should be 1000 for full ImageNet

# Preprocess the data
def preprocess(example):
    image = tf.cast(example['image'], tf.float32) / 255.0  # Normalize to [0, 1]
    label = tf.one_hot(example['label'], num_classes)  # One-hot encode labels
    return image, label

# Apply preprocessing
train_dataset = train_dataset.map(preprocess).batch(128).prefetch(tf.data.AUTOTUNE)
test_dataset = test_dataset.map(preprocess).batch(128).prefetch(tf.data.AUTOTUNE)

# Define the teacher model which is a CNN
def create_model():
    model = tf.keras.Sequential([
        tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=(32, 32, 3)),
        tf.keras.layers.MaxPooling2D(),
        tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
        tf.keras.layers.MaxPooling2D(),
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(256, activation='relu'),
        tf.keras.layers.Dense(num_classes, activation='softmax')  # Output layer should match num_classes
    ])
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

# Train teacher model
teacher_model = create_model()
teacher_model.fit(train_dataset, epochs=10, validation_data=test_dataset)

# Generate soft targets for each batch in train_dataset
def generate_soft_targets(model, dataset):
    soft_targets = []
    for images, _ in dataset:
        logits = model(images)
        soft_targets.append(tf.nn.softmax(logits))  # Get soft targets for each batch
    return tf.concat(soft_targets, axis=0)  # Concatenate all soft targets into a single tensor

# Generate soft targets from the teacher model
soft_targets = generate_soft_targets(teacher_model, train_dataset)

# Create a mapping function to pair images with their corresponding soft targets
#map_soft_targets will take the batch of input images as first argument and the second one is ignored as student model will not use ground truth labels
def map_soft_targets(images, _):
    batch_size = tf.shape(images)[0]
    indices = tf.range(batch_size)
    soft_target_batch = tf.gather(soft_targets, indices)
    return images, soft_target_batch
#Set the value for the temperature parameter which will scale the logits
temperature=5
# Create a generator which has the mapping to soft targets for training the student model
train_generator = train_dataset.map(map_soft_targets).prefetch(tf.data.AUTOTUNE)

#This loss uses temperature scaling factor `temp` to smoothen the probabilities during training so that the student model learns from smoother decision boundaries.
def distillation_loss(y_true, y_pred, temp):
    """
    Custom loss for distillation.
    """
    y_true_scaled = y_true / temp
    y_pred_scaled = y_pred / temp
    return tf.reduce_mean(
        tf.nn.softmax_cross_entropy_with_logits(labels=y_true_scaled, logits=y_pred_scaled)
    )
# Student model uses the same architecture as teacher model
student_model = create_model()

student_model.compile(
    optimizer='adam',
    loss=lambda y_true, y_pred: distillation_loss(y_true, y_pred, temperature),
    metrics=['accuracy']
)

#Student model is trained using the train_generator which has the mapping of images with their associated soft targets
student_model.fit(train_generator, epochs=10, validation_data=test_dataset)

# Evaluate models
teacher_loss, teacher_accuracy = teacher_model.evaluate(test_dataset)
student_loss, student_accuracy = student_model.evaluate(test_dataset)

#Get the accuracy result of teacher and student models on original data
print(f'Teacher Model Accuracy on Clean Data: {teacher_accuracy:.4f}')
print(f'Student Model Accuracy on Clean Data: {student_accuracy:.4f}')

def fgsm_attack(model, images, labels, epsilon=0.02):
    """
    Generate adversarial examples using the FGSM attack.

    Args:
        model: The trained model to attack.
        images: Input images.
        labels: True labels for the images.
        epsilon: Perturbation magnitude.

    Returns:
        adversarial_examples: Adversarially perturbed images.
    """
    images = tf.cast(images, tf.float32)  # Ensure images are in float32
    labels = tf.cast(labels, tf.float32)

    with tf.GradientTape() as tape:
        tape.watch(images)  # Watch the input images
        predictions = model(images)  # Get predictions
        loss = tf.keras.losses.categorical_crossentropy(labels, predictions)  # Compute loss

    # Compute the gradient of the loss w.r.t. input images
    gradient = tape.gradient(loss, images)

    # Compute the signed gradient (direction of increase in loss)
    signed_gradient = tf.sign(gradient)

    # Generate adversarial examples by adding the perturbation
    adversarial_examples = images + epsilon * signed_gradient

    # Clip the adversarial examples to stay within the valid range [0, 1]
    adversarial_examples = tf.clip_by_value(adversarial_examples, 0, 1)

    return adversarial_examples

# Generate adversarial examples for the test dataset
def generate_adversarial_test_data(model, test_dataset, epsilon=0.02):
    adversarial_images, adversarial_labels = [], []
    for images, labels in test_dataset:
        # Generate adversarial examples for the batch using FGSM attack
        adversarial_batch = fgsm_attack(model, images, labels, epsilon=epsilon)
        adversarial_images.append(adversarial_batch)
        adversarial_labels.append(labels)
    # Concatenate batches
    return tf.concat(adversarial_images, axis=0), tf.concat(adversarial_labels, axis=0)

# Generate adversarial test data
adv_test_images, adv_test_labels = generate_adversarial_test_data(teacher_model, test_dataset, epsilon=0.02)

# Evaluate models on adversarial data
print("Evaluating on Adversarial Examples...")

teacher_loss, teacher_accuracy = teacher_model.evaluate(tf.data.Dataset.from_tensor_slices((adv_test_images, adv_test_labels)).batch(128))
student_loss, student_accuracy = student_model.evaluate(tf.data.Dataset.from_tensor_slices((adv_test_images, adv_test_labels)).batch(128))

#Accuracy of teacher and student models on adversarial examples generated using FGSM attack
print(f"Teacher Model Accuracy on Adversarial Examples: {teacher_accuracy:.4f}")
print(f"Student Model Accuracy on Adversarial Examples: {student_accuracy:.4f}")

# Experiment with different epsilon values

epsilons = [0.01, 0.02, 0.05]

for eps in epsilons:
    print(f"\nEvaluating models with epsilon = {eps}...")
    adv_images, adv_labels = generate_adversarial_test_data(teacher_model, test_dataset, epsilon=eps)
    teacher_loss, teacher_acc = teacher_model.evaluate(tf.data.Dataset.from_tensor_slices((adv_images, adv_labels)).batch(128))
    student_loss, student_acc = student_model.evaluate(tf.data.Dataset.from_tensor_slices((adv_images, adv_labels)).batch(128))
    print(f"Epsilon = {eps} | Teacher Accuracy: {teacher_acc:.4f} | Student Accuracy: {student_acc:.4f}")

import pandas as pd

# Define a range of epsilon values
epsilons = [0.01, 0.02, 0.05]

# Initialize a list to store results
results = []

# Evaluate both models for each epsilon
for eps in epsilons:
    print(f"\nEvaluating models with epsilon = {eps}...")

    # Generate adversarial test data
    adv_images, adv_labels = generate_adversarial_test_data(teacher_model, test_dataset, epsilon=eps)
    adv_test_dataset = tf.data.Dataset.from_tensor_slices((adv_images, adv_labels)).batch(128)

    # Evaluate teacher model
    teacher_loss, teacher_acc = teacher_model.evaluate(adv_test_dataset, verbose=0)

    # Evaluate student model
    student_loss, student_acc = student_model.evaluate(adv_test_dataset, verbose=0)

    # Store the results
    results.append({
        "Epsilon": eps,
        "Teacher Accuracy": teacher_acc,
        "Student Accuracy": student_acc
    })

# Convert results to a DataFrame for better readability
results_df = pd.DataFrame(results)

# Print results as a table
print("\nAdversarial Robustness Comparison:\n")
print(results_df.to_string(index=False))  # Nice tabular format

#Plot results for visual comparison
import matplotlib.pyplot as plt

# Plot Teacher and Student Accuracy
plt.figure(figsize=(8, 6))
plt.plot(results_df["Epsilon"], results_df["Teacher Accuracy"], label="Teacher Accuracy", marker="o")
plt.plot(results_df["Epsilon"], results_df["Student Accuracy"], label="Student Accuracy", marker="o")
plt.title("Adversarial Robustness Comparison")
plt.xlabel("Epsilon (Perturbation Magnitude)")
plt.ylabel("Accuracy")
plt.legend()
plt.grid(True)
plt.show()

"""**Defensive Distillation (Adversarial Patch)**




"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
from tqdm import tqdm
import numpy as np
import os
import matplotlib.pyplot as plt

# Device configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Constants (update based on your dataset and setup)
NORM_MEAN = [0.485, 0.456, 0.406]
NORM_STD = [0.229, 0.224, 0.225]
# Example labels
label_names = ["goldfish", "toaster", "school bus", "pineapple", "lipstick"]
# Classes to evaluate adversarial patch attacks on
class_names = label_names  # Subset of label names to attack
# Different sizes of adversarial patches we have considered for our attack
patch_sizes = [32, 48, 64]

# Tensor means and stds for patch normalization
TENSOR_MEANS = torch.FloatTensor(NORM_MEAN)[:, None, None]
TENSOR_STD = torch.FloatTensor(NORM_STD)[:, None, None]

# Dataset transformations
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=NORM_MEAN, std=NORM_STD)
])

# Load dataset
val_dataset = datasets.FakeData(size=100, transform=transform)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)

# We have defined a dummy model for testing purposes (We have replaced it with our trained teacher and student models )
class DummyModel(nn.Module):
    def __init__(self, num_classes=5):
        super(DummyModel, self).__init__()
        self.fc = nn.Linear(224 * 224 * 3, num_classes)

    def forward(self, x):
        # Flatten the input
        x = x.view(x.size(0), -1)
        return self.fc(x)

# Initialize the teacher and student models
teacher_model = DummyModel(len(label_names)).to(device)
student_model = DummyModel(len(label_names)).to(device)

# Function to place the adversarial patch on an image
def place_patch(img, patch):
    """
    Place the adversarial patch randomly on the image.
    """
    for i in range(img.shape[0]):
        h_offset = np.random.randint(0, img.shape[2] - patch.shape[1] - 1)
        w_offset = np.random.randint(0, img.shape[3] - patch.shape[2] - 1)
        img[i, :, h_offset:h_offset + patch.shape[1], w_offset:w_offset + patch.shape[2]] = patch_forward(patch)
    return img


# Patch normalization function to normalize the patch to dataset range
def patch_forward(patch):
    """
    Normalize the patch to the same range as the dataset (e.g., ImageNet).
    """
    means = TENSOR_MEANS.to(patch.device)
    std = TENSOR_STD.to(patch.device)
    patch = (torch.tanh(patch) + 1 - 2 * means) / (2 * std)
    return patch


# Evaluation a model's robustness against an adversarial patch
def eval_patch_on_model(model, patch, val_loader, target_class):
    """
    Evaluate a model's robustness against an adversarial patch.
    """
    model.eval()  # Set the model to evaluation mode
    tp, tp_5, counter = 0., 0., 0.

    with torch.no_grad():
        for img, img_labels in tqdm(val_loader, desc="Validating Model...", leave=False):
            for _ in range(4):  # Test 4 random placements for stability
                patch_img = place_patch(img.clone(), patch)  # Clone to avoid modifying original images
                patch_img = patch_img.to(device)
                img_labels = img_labels.to(device)

                pred = model(patch_img)

                # Move predictions and labels to CPU before calculations
                pred = pred.cpu()
                img_labels_cpu = img_labels.cpu()

                # Calculate true positives and top-5 accuracy
                tp += torch.logical_and(pred.argmax(dim=-1) == target_class, img_labels_cpu != target_class).sum().item()
                tp_5 += torch.logical_and((pred.topk(5, dim=-1)[1] == target_class).any(dim=-1), img_labels_cpu != target_class).sum().item()
                counter += (img_labels_cpu != target_class).sum().item()
    #Compute accuracy metrics
    acc = tp / counter if counter > 0 else 0  # Accuracy
    top5 = tp_5 / counter if counter > 0 else 0  # Top-5 accuracy
    return float(acc), float(top5)


# Visualization function for patches
def show_patches(patch_dict):
    fig, ax = plt.subplots(len(patch_sizes), len(class_names), figsize=(len(class_names)*2.2, len(patch_sizes)*2.2))

    for c_idx, cname in enumerate(class_names):
        for p_idx, psize in enumerate(patch_sizes):
            if psize in patch_dict[cname]:
                patch = patch_dict[cname][psize]["patch"]
                patch_img = (torch.tanh(patch) + 1) / 2  # Normalize to [0, 1]
                patch_img = patch_img.cpu().permute(1, 2, 0).numpy()
                ax[p_idx][c_idx].imshow(np.clip(patch_img, a_min=0.0, a_max=1.0))
                ax[p_idx][c_idx].set_title(f"{cname}, size {psize}")
                ax[p_idx][c_idx].axis('off')

    fig.subplots_adjust(hspace=0.3, wspace=0.3)
    plt.show()


# Main evaluation loop for teacher and student models
patch_dict = {}

for class_name in class_names:
    target_class = label_names.index(class_name)

    for patch_size in patch_sizes:
        str_patch_size = str(patch_size)

        # Create a patch (replace with pre-trained patch if available)
        patch = nn.Parameter(torch.zeros(3, patch_size, patch_size)).to(device)

        # Evaluate on teacher model
        teacher_acc, teacher_top5 = eval_patch_on_model(teacher_model, patch, val_loader, target_class)
        print(f"Teacher Model - Class: {class_name}, Patch Size: {patch_size}, Acc: {teacher_acc:.4f}, Top-5 Acc: {teacher_top5:.4f}")

        # Evaluate on student model
        student_patch = patch.to(device)  # Ensure patch is on the correct device
        student_acc, student_top5 = eval_patch_on_model(student_model, student_patch, val_loader, target_class)
        print(f"Student Model - Class: {class_name}, Patch Size: {patch_size}, Acc: {student_acc:.4f}, Top-5 Acc: {student_top5:.4f}")

import pandas as pd
import matplotlib.pyplot as plt

# Store results in a list
results = []

# Main evaluation loop for teacher and student models
for class_name in class_names:
    target_class = label_names.index(class_name)

    for patch_size in patch_sizes:
        # Create or load a patch
        patch = nn.Parameter(torch.zeros(3, patch_size, patch_size)).to(device)  # Replace with pre-trained patch

        # Evaluate on teacher model
        teacher_acc, teacher_top5 = eval_patch_on_model(teacher_model, patch, val_loader, target_class)

        # Evaluate on student model
        student_patch = patch.to(device)
        student_acc, student_top5 = eval_patch_on_model(student_model, student_patch, val_loader, target_class)

        # Append results
        results.append({
            "Class": class_name,
            "Patch Size": patch_size,
            "Teacher Accuracy": teacher_acc,
            "Teacher Top-5 Accuracy": teacher_top5,
            "Student Accuracy": student_acc,
            "Student Top-5 Accuracy": student_top5
        })

# Convert results to a DataFrame
results_df = pd.DataFrame(results)

# Display the results as a table
print(results_df)

# Save the results to a CSV file (optional)
results_df.to_csv("adversarial_patch_results.csv", index=False)

# Plot the results
def plot_results(results_df):
    """
    Plot the results for teacher and student models.
    """
    for class_name in class_names:
        class_results = results_df[results_df["Class"] == class_name]

        # Plot Teacher vs Student accuracy for the class
        plt.figure(figsize=(8, 6))
        plt.plot(class_results["Patch Size"], class_results["Teacher Accuracy"], marker="o", label="Teacher Accuracy")
        plt.plot(class_results["Patch Size"], class_results["Student Accuracy"], marker="o", label="Student Accuracy")
        plt.title(f"Robustness Against Patches - {class_name}")
        plt.xlabel("Patch Size")
        plt.ylabel("Accuracy")
        plt.legend()
        plt.grid(True)
        plt.show()

# Generate plots
plot_results(results_df)

"""**Defense mechanism (In Progress)**

##Adversarial Training
"""

import tensorflow as tf
import tensorflow_datasets as tfds

# Load a subset of ImageNet
dataset, info = tfds.load('imagenet_resized/32x32', split=['train[:10%]', 'validation[:10%]'], with_info=True)
train_ds, test_ds = dataset
num_classes = info.features['label'].num_classes


# Load ImageNet dataset
#(train_ds, test_ds), info = tfds.load('imagenet2012', split=['train[:10%]', 'validation[:10%]'], with_info=True, as_supervised=True)
#num_classes = info.features['label'].num_classes

# Preprocess function

def preprocess(example):
    image = example['image']
    label = example['label']
    image = tf.image.resize(image, (224, 224))
    image = tf.keras.applications.resnet50.preprocess_input(image)
    return image, tf.one_hot(label, num_classes)

# Apply preprocessing
train_ds = train_ds.map(preprocess).batch(128).prefetch(tf.data.AUTOTUNE)
test_ds = test_ds.map(preprocess).batch(128).prefetch(tf.data.AUTOTUNE)

def create_model():
    base_model = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_shape=(224, 224, 3))
    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)
    output = tf.keras.layers.Dense(num_classes, activation='softmax')(x)
    model = tf.keras.Model(inputs=base_model.input, outputs=output)
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

def adversarial_train(model, train_ds, epochs, epsilon):
    for epoch in range(epochs):
        print(f"Epoch {epoch+1}/{epochs}")
        for images, labels in train_ds:
            # Generate adversarial examples
            adv_images = generate_adversarial_examples(model, images, labels, epsilon)

            # Combine clean and adversarial examples
            combined_images = tf.concat([images, adv_images], axis=0)
            combined_labels = tf.concat([labels, labels], axis=0)

            # Train on combined data
            model.train_on_batch(combined_images, combined_labels)

        # Evaluate after each epoch
        clean_loss, clean_acc = model.evaluate(test_ds, verbose=0)
        adv_images = generate_adversarial_examples(model, next(iter(test_ds))[0], next(iter(test_ds))[1], epsilon)
        adv_loss, adv_acc = model.evaluate(tf.data.Dataset.from_tensor_slices((adv_images, next(iter(test_ds))[1])).batch(128), verbose=0)
        print(f"Clean Test Accuracy: {clean_acc:.4f}, Adversarial Test Accuracy: {adv_acc:.4f}")

model = create_model()
adversarial_train(model, train_ds, epochs=1, epsilon=0.1)

# Final evaluation
clean_loss, clean_acc = model.evaluate(test_ds, verbose=0)
adv_images = generate_adversarial_examples(model, next(iter(test_ds))[0], next(iter(test_ds))[1], epsilon=0.1)
adv_loss, adv_acc = model.evaluate(tf.data.Dataset.from_tensor_slices((adv_images, next(iter(test_ds))[1])).batch(128), verbose=0)

print(f"Final Clean Test Accuracy: {clean_acc:.4f}")
print(f"Final Adversarial Test Accuracy: {adv_acc:.4f}")